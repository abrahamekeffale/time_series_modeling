{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\HP\\week 11 final\\time_series_modeling\\scripts')  \n",
    "\n",
    "import data_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\HP\\week 11 final\\time_series_modeling\\scripts\\data_loading.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the preprocessed data from data_loading.py\n",
    "data = data_loading.load_stock_data(\"TSLA\", \"2015-01-01\", \"2024-10-31\")\n",
    "preprocessed_data = data_loading.preprocess_data(data)\n",
    "\n",
    "# Extract closing prices for TSLA\n",
    "tsla_close = preprocessed_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split \n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02 00:00:00+00:00</th>\n",
       "      <td>14.620667</td>\n",
       "      <td>14.620667</td>\n",
       "      <td>14.883333</td>\n",
       "      <td>14.217333</td>\n",
       "      <td>14.858000</td>\n",
       "      <td>71466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 00:00:00+00:00</th>\n",
       "      <td>14.006000</td>\n",
       "      <td>14.006000</td>\n",
       "      <td>14.433333</td>\n",
       "      <td>13.810667</td>\n",
       "      <td>14.303333</td>\n",
       "      <td>80527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06 00:00:00+00:00</th>\n",
       "      <td>14.085333</td>\n",
       "      <td>14.085333</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>13.614000</td>\n",
       "      <td>14.004000</td>\n",
       "      <td>93928500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07 00:00:00+00:00</th>\n",
       "      <td>14.063333</td>\n",
       "      <td>14.063333</td>\n",
       "      <td>14.318667</td>\n",
       "      <td>13.985333</td>\n",
       "      <td>14.223333</td>\n",
       "      <td>44526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08 00:00:00+00:00</th>\n",
       "      <td>14.041333</td>\n",
       "      <td>14.041333</td>\n",
       "      <td>14.253333</td>\n",
       "      <td>14.000667</td>\n",
       "      <td>14.187333</td>\n",
       "      <td>51637500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Adj Close      Close       High        Low  \\\n",
       "Ticker                          TSLA       TSLA       TSLA       TSLA   \n",
       "Date                                                                    \n",
       "2015-01-02 00:00:00+00:00  14.620667  14.620667  14.883333  14.217333   \n",
       "2015-01-05 00:00:00+00:00  14.006000  14.006000  14.433333  13.810667   \n",
       "2015-01-06 00:00:00+00:00  14.085333  14.085333  14.280000  13.614000   \n",
       "2015-01-07 00:00:00+00:00  14.063333  14.063333  14.318667  13.985333   \n",
       "2015-01-08 00:00:00+00:00  14.041333  14.041333  14.253333  14.000667   \n",
       "\n",
       "Price                           Open    Volume  \n",
       "Ticker                          TSLA      TSLA  \n",
       "Date                                            \n",
       "2015-01-02 00:00:00+00:00  14.858000  71466000  \n",
       "2015-01-05 00:00:00+00:00  14.303333  80527500  \n",
       "2015-01-06 00:00:00+00:00  14.004000  93928500  \n",
       "2015-01-07 00:00:00+00:00  14.223333  44526000  \n",
       "2015-01-08 00:00:00+00:00  14.187333  51637500  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (assuming you have a CSV file with 'Date' and 'Adj Close' columns)\n",
    "data = preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def create_dataset(dataset, look_back=60):\n",
    "  X, y = [], []\n",
    "  for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back), 0]\n",
    "    X.append(a)\n",
    "    y.append(dataset[i + look_back, 0])\n",
    "  return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['Adj Close'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "test_size = len(scaled_data) - train_size\n",
    "train, test = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be [samples, time steps, features]\n",
    "look_back = 60\n",
    "X_train, y_train = create_dataset(train, look_back)\n",
    "X_test, y_test = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Early Stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)  # Monitor validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 0.0221 - val_loss: 0.0021\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 7.6724e-04 - val_loss: 0.0016\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 9.4037e-04 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 7.9611e-04 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 5.1792e-04 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "# Train the model with Early Stopping\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model:\n",
      "Mean Squared Error: 52052.33836658447\n",
      "Root Mean Squared Error: 228.14981561812507\n",
      "Mean Absolute Error: 225.67949432091103\n",
      "Mean Absolute Percentage Error: 442.48097961647824\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "\n",
    "print('LSTM Model:')\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Absolute Percentage Error:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Define seasonal parameters (adjust values as needed)\n",
    "p, d, q = 1, 1, 1\n",
    "seasonal_period = 12  # Or a more descriptive name\n",
    "\n",
    "# Fit the SARIMA model\n",
    "model = SARIMAX(adjusted_close, order=(p, d, q), seasonal_order=(1, 1, 1, seasonal_period))\n",
    "model_fit = model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
