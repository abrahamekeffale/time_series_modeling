{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\HP\\week 11 final\\time_series_modeling\\scripts')  \n",
    "\n",
    "import data_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\HP\\week 11 final\\time_series_modeling\\scripts\\data_loading.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the preprocessed data from data_loading.py\n",
    "data = data_loading.load_stock_data(\"TSLA\", \"2015-01-01\", \"2024-10-31\")\n",
    "preprocessed_data = data_loading.preprocess_data(data)\n",
    "\n",
    "# Extract closing prices for TSLA\n",
    "tsla_close = preprocessed_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split \n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data here (assuming 'Close' column contains the target time series)\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "# data = df['Close'].squeeze()  # Ensure data is a Series\n",
    "\n",
    "# Check for stationarity and apply differencing if needed\n",
    "def check_stationarity(timeseries, significance_level=0.05):\n",
    "    result = adfuller(timeseries)\n",
    "    print(f\"ADF Statistic: {result[0]}\")\n",
    "    print(f\"p-value: {result[1]}\")\n",
    "    return result[1] < significance_level  # True if stationary\n",
    "\n",
    "# Differencing to make the data stationary if needed\n",
    "def make_stationary(data, max_diff_order=2):\n",
    "    diff_order = 0\n",
    "    while diff_order < max_diff_order:\n",
    "        if check_stationarity(data):\n",
    "            break\n",
    "        data = data.diff().dropna().squeeze()  # Ensure it's a Series after differencing\n",
    "        diff_order += 1\n",
    "    return data, diff_order\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data, test_data = data[:train_size].squeeze(), data[train_size:].squeeze()  # Ensure both are Series\n",
    "\n",
    "# Check stationarity and apply differencing if needed\n",
    "stationary_data, diff_order = make_stationary(train_data)\n",
    "\n",
    "# Define ARIMA model with adjusted parameters\n",
    "p, d, q = 5, diff_order, 0  # Starting values for (p, d, q)\n",
    "\n",
    "# Fit the ARIMA model with error handling\n",
    "try:\n",
    "    arima_model = ARIMA(stationary_data, order=(p, d, q))\n",
    "    arima_fit = arima_model.fit()\n",
    "    print(\"Model fitted successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting ARIMA model: {e}\")\n",
    "\n",
    "# Forecast for the test data period\n",
    "try:\n",
    "    forecast_steps = len(test_data)\n",
    "    arima_forecast = arima_fit.forecast(steps=forecast_steps)\n",
    "    \n",
    "    # Reverse differencing if needed\n",
    "    if diff_order > 0:\n",
    "        for _ in range(diff_order):\n",
    "            arima_forecast = arima_forecast.cumsum() + train_data.iloc[-1]\n",
    "\n",
    "    # Calculate Mean Squared Error\n",
    "    mse = mean_squared_error(test_data, arima_forecast)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "    # Plotting the actual vs predicted values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_data.index, train_data, label='Training Data')\n",
    "    plt.plot(test_data.index, test_data, label='Actual Data', color='blue')\n",
    "    plt.plot(test_data.index, arima_forecast, label='Forecasted Data', color='red')\n",
    "    plt.legend()\n",
    "    plt.title(\"ARIMA Model - Actual vs Forecasted\")\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in forecasting: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SARIMAX models require univariate `endog`. Got shape (1979, 6).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstatespace\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarimax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SARIMAX\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Fit the SARIMA model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sarima_model \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAX\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m sarima_fit \u001b[38;5;241m=\u001b[39m sarima_model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Forecast\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:328\u001b[0m, in \u001b[0;36mSARIMAX.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, measurement_error, time_varying_regression, mle_regression, simple_differencing, enforce_stationarity, enforce_invertibility, hamilton_representation, concentrate_scale, trend_offset, use_exact_diffuse, dates, freq, missing, validate_specification, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    319\u001b[0m              seasonal_order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m              measurement_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, time_varying_regression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m              freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, validate_specification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    326\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAXSpecification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_stationarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_invertibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcentrate_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentrate_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_specification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_specification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m SARIMAXParams(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec)\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# Save given orders\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\statsmodels\\tsa\\arima\\specification.py:454\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# Validate endog shape\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (validate_specification \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m faux_endog \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSARIMAX models require univariate `endog`. Got\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    455\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_missing \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)))\n",
      "\u001b[1;31mValueError\u001b[0m: SARIMAX models require univariate `endog`. Got shape (1979, 6)."
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Fit the SARIMA model\n",
    "sarima_model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_fit = sarima_model.fit()\n",
    "\n",
    "# Forecast\n",
    "sarima_forecast = sarima_fit.forecast(steps=len(test))\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(test, sarima_forecast)\n",
    "rmse = np.sqrt(mean_squared_error(test, sarima_forecast))\n",
    "print(f\"SARIMA MAE: {mae}, RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - loss: 0.0272\n",
      "Epoch 2/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0018\n",
      "Epoch 3/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0011\n",
      "Epoch 4/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0011\n",
      "Epoch 5/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 8.3635e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 9.7606e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 8.0694e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 8.9807e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.2142e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 6.1634e-04\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (434,1) doesn't match the broadcast shape (434,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m lstm_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Ensure inverse transform applies only to the target feature\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m lstm_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_predictions\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Inverse transform the predictions\u001b[39;00m\n\u001b[0;32m     56\u001b[0m y_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Reshape y_test to (n_samples, 1) and inverse transform\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Evaluate and plot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\week 11 final\\time_series_modeling\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:574\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    564\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    566\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    567\u001b[0m     X,\n\u001b[0;32m    568\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    571\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    572\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_\u001b[49m\n\u001b[0;32m    575\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (434,1) doesn't match the broadcast shape (434,6)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'Close' is the target time series\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# target_data = df[['Close']].values  # Select only 'Close' for scaling\n",
    "\n",
    "# Scale only the target variable\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Define parameters\n",
    "time_step = 60\n",
    "\n",
    "# Convert data into sequences for LSTM\n",
    "def create_sequences(data, time_step):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 0])  # Use only the target feature\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data, test_data = scaled_data[:train_size], scaled_data[train_size:]\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, time_step)\n",
    "X_test, y_test = create_sequences(test_data, time_step)\n",
    "\n",
    "# Reshape inputs to be [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dense(25),\n",
    "    Dense(1)  # Output layer with a single neuron for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "# Make predictions and reverse scaling\n",
    "lstm_predictions = model.predict(X_test)\n",
    "\n",
    "# Ensure inverse transform applies only to the target feature\n",
    "lstm_predictions = scaler.inverse_transform(lstm_predictions)  # Inverse transform the predictions\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))  # Reshape y_test to (n_samples, 1) and inverse transform\n",
    "\n",
    "# Evaluate and plot\n",
    "mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Plot actual vs. predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, label=\"Actual\")\n",
    "plt.plot(lstm_predictions, label=\"Predicted\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Close Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target_data: (2474, 6)\n",
      "Shape of scaled_data: (2474, 6)\n",
      "Shape of X_train: (1918, 60, 1)\n",
      "Shape of y_train: (1918,)\n",
      "Shape of X_test: (434, 60, 1)\n",
      "Shape of y_test before reshaping: (434,)\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Shape of lstm_predictions before inverse transform: (434, 1)\n",
      "Shape of y_test after reshaping: (434, 1)\n",
      "Inverse transform error: non-broadcastable output operand with shape (434,1) doesn't match the broadcast shape (434,6)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of data involved in scaling and predictions\n",
    "print(\"Shape of target_data:\", data.shape)  # Target column before scaling\n",
    "print(\"Shape of scaled_data:\", scaled_data.shape)  # Data after scaling\n",
    "print(\"Shape of X_train:\", X_train.shape)          # Training input features\n",
    "print(\"Shape of y_train:\", y_train.shape)          # Training target\n",
    "print(\"Shape of X_test:\", X_test.shape)            # Testing input features\n",
    "print(\"Shape of y_test before reshaping:\", y_test.shape)  # Testing target before reshaping\n",
    "\n",
    "# Run LSTM prediction\n",
    "lstm_predictions = model.predict(X_test)\n",
    "print(\"Shape of lstm_predictions before inverse transform:\", lstm_predictions.shape)  # Predictions shape\n",
    "\n",
    "# Reshape y_test to ensure it has a compatible shape for inverse scaling\n",
    "y_test = y_test.reshape(-1, 1)  # Reshape y_test to (n_samples, 1)\n",
    "print(\"Shape of y_test after reshaping:\", y_test.shape)\n",
    "\n",
    "# Attempt inverse transform on predictions and y_test\n",
    "try:\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)  # Inverse scale predictions\n",
    "    y_test = scaler.inverse_transform(y_test)  # Inverse scale actual values\n",
    "    print(\"Inverse transform successful.\")\n",
    "except ValueError as e:\n",
    "    print(\"Inverse transform error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
